{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palabras autoreferentes\n",
    "En este script buscamos las palabras que ene el grafo tienen un bucle y ver su contexto, es decir mostrar su párrafo. Para lo cual modificamos el código que genera el grafo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk#librería para el tratamiento sintáctico\n",
    "from itertools import imap,ifilter,islice,repeat#tanto imap como ifilter son iteradores, son usados\n",
    "               #por razones de eficiencia ver https://docs.python.org/2/library/itertools.html\n",
    "import networkx as nx\n",
    "from nltk.stem import SnowballStemmer\n",
    "spanish_stemmer = SnowballStemmer(\"spanish\")\n",
    "#ajustamos el sistema para tratar el utf-8:\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "def pairwise(iterable):\n",
    "    \"\"\"otro iterador:(extraido de https://docs.python.org/2/library/itertools.html)\n",
    "    s -> (s0,s1), (s1,s2), (s2, s3), ...\n",
    "    \"\"\"\n",
    "    a, b = next(iterable),next(iterable),\n",
    "    while 1:\n",
    "        yield (a, b)\n",
    "        a,b=b,next(iterable)\n",
    "endphase='.!?¿!-;.:'\n",
    "import stop_words\n",
    "stopwords=stop_words.get_stop_words(u'spanish')#cargamos las stopwords del idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text=open('BIBLIA.txt','r').read()\n",
    "raw=str.decode( text,'utf8')\n",
    "tokens = nltk.word_tokenize(raw,'spanish')\n",
    "tokensLow=imap(unicode.lower,tokens)\n",
    "from collections import defaultdict\n",
    "root_original=defaultdict(set)\n",
    "def getroot(original):\n",
    "    root=spanish_stemmer.stem(original)\n",
    "    root_original[root].add(original)\n",
    "    return root\n",
    "relevantWords=imap(getroot,ifilter(lambda x: not(x in stopwords), tokensLow) )\n",
    "digits='01234566789&#()[]'\n",
    "def punt_gestion(pairs):\n",
    "    for (a,b) in pairs:\n",
    "        if a in endphase or b in endphase or (a[0] in digits) or (b[0] in digits):\n",
    "            pass\n",
    "        else:\n",
    "            yield (a,b)\n",
    "parejas=(punt_gestion(pairwise(ifilter(lambda x: not(x in ','),relevantWords) )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección el código se modifica para retener en un diccionario (pareja_rep_frase) las palabras autorrferenciadas$\\rightarrow$ numero parrafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_original=defaultdict(set)\n",
    "line=defaultdict(list)\n",
    "from itertools import imap,ifilter,islice,repeat,izip\n",
    "def getroot(original,n):\n",
    "    root=spanish_stemmer.stem(original)\n",
    "    root_original[root].add(original)\n",
    "    line[root].append(n)\n",
    "    return root\n",
    "def punt_gestion(pairs):\n",
    "        for (a,b) in pairs:\n",
    "            if a in endphase or b in endphase or (a[0] in digits) or (b[0] in digits):\n",
    "                pass\n",
    "            else:\n",
    "                yield (a,b)\n",
    "text=enumerate(open('BIBLIA.txt','r'))\n",
    "pareja_rep_frase=defaultdict(set)\n",
    "def app(set,(pairword,numparr) ):\n",
    "    if pairword[0]==pairword[1]:\n",
    "        set[pairword].add(numparr)\n",
    "    return set\n",
    "for numparr,parr in text:\n",
    "    raw=str.decode( parr,'utf8')\n",
    "    tokens = nltk.word_tokenize(raw,'spanish')\n",
    "    tokensLow=imap(unicode.lower,tokens)\n",
    "    relevantWords=imap(getroot,ifilter(lambda x: not(x in stopwords), tokensLow) ,repeat(numparr))\n",
    "    digits='01234566789&#()[]'\n",
    "    \n",
    "    pareja_rep_frase=reduce(app,izip(punt_gestion(pairwise(ifilter(lambda x: not(x in ','),relevantWords) )),repeat(numparr)),pareja_rep_frase)\n",
    "pareja_rep_frase=dict([(a,b) for a,b in pareja_rep_frase.iteritems() if len(b)>5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text=list(open('BIBLIA.txt','r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribimos los resultados en [extractosRep.txt](extractosRep.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_=lambda x:(a,text[x])\n",
    "r=[]\n",
    "f=open('extractosRep.txt','w')\n",
    "for i in [map(text_ ,list(b)[:2] )   for (a,b) in pareja_rep_frase.items()]:#[[((word,word),)]]\n",
    "    for j in i:\n",
    "        ((w,w),xs)=j\n",
    "        r.append(w)\n",
    "        f.write('\\n\\n')\n",
    "        f.write(w+':\\n\\n')\n",
    "        f.write((xs))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
